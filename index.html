<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Yibo Liu</title>
    <meta name="description" content="Personal webpage">
    <link rel="icon" href="/logo.png">
    
    <link rel="preload" href="/assets/css/0.styles.3cf5ef1f.css" as="style"><link rel="preload" href="/assets/js/app.da6b8446.js" as="script"><link rel="preload" href="/assets/js/2.4d7c2de1.js" as="script"><link rel="preload" href="/assets/js/7.9b937e51.js" as="script"><link rel="preload" href="/assets/js/4.80216183.js" as="script"><link rel="preload" href="/assets/js/5.93671bdf.js" as="script"><link rel="prefetch" href="/assets/js/10.828fe095.js"><link rel="prefetch" href="/assets/js/11.73363121.js"><link rel="prefetch" href="/assets/js/12.66224500.js"><link rel="prefetch" href="/assets/js/13.00c9c0ca.js"><link rel="prefetch" href="/assets/js/14.51cd99da.js"><link rel="prefetch" href="/assets/js/15.79ceeeca.js"><link rel="prefetch" href="/assets/js/16.f6eebb3f.js"><link rel="prefetch" href="/assets/js/17.20e8b7a5.js"><link rel="prefetch" href="/assets/js/18.8645afb5.js"><link rel="prefetch" href="/assets/js/3.a28516b4.js"><link rel="prefetch" href="/assets/js/6.d86c8b7f.js"><link rel="prefetch" href="/assets/js/8.250fbf9b.js"><link rel="prefetch" href="/assets/js/9.fcb7dc63.js">
    <link rel="stylesheet" href="/assets/css/0.styles.3cf5ef1f.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar home-page"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-exact-active router-link-active"><!----> <span class="site-name">Yibo Liu</span></a> <div class="links"><!----> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link router-link-exact-active router-link-active">Home</a></div><div class="nav-item"><a href="/article/" class="nav-link">Blog</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link router-link-exact-active router-link-active">Home</a></div><div class="nav-item"><a href="/article/" class="nav-link">Blog</a></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><div class="profile"><div class="image"><img src="/myprofile2.jpeg" alt></div> <div class="info"><div class="name">
      Yibo Liu
    </div> <div class="bio"><p>Computer Science</p></div> <div class="socials"><div><a href="https://scholar.google.com/citations?user=FQExy98AAAAJ&amp;hl=en&amp;oi=ao" target="_blank"><img src="/icons/google-scholar.svg" alt="google-scholar" title="google-scholar"></a></div><div><a href="https://github.com/xDarkLemon" target="_blank"><img src="/icons/github.svg" alt="github" title="github"></a></div><div><a href="https://twitter.com/_liuyibo" target="_blank"><img src="/icons/twitter.svg" alt="twitter" title="twitter"></a></div></div> <div class="contact"><div title="Contact me" class="email">yl6769 (at) nyu (dot) edu</div></div> <!----></div></div> <h2 id="about">About</h2> <p>I am Yibo Liu, a first year Ph.D. student in Computer Science at University of Victoria. Prior to this, I obtained my M.S. in Computer Science from New York University, where I conducted research on multimodal knowledge graph representation learning. I obtained B.Eng. in Electronic Engineering from Beijing University of Posts and Telecommunications. My industrial experience includes an internship at Data, Knowledge and Intelligence group at Microsoft Research Asia.</p> <h2 id="education">Education</h2> <ul><li><p><strong>University of Victoria</strong> <br>
Ph.D. in Computer Science, Sept 2023 - present</p></li> <li><p><strong>New York University</strong> <br>
M.S. in Computer Science, Sept 2019 - Dec 2022</p></li> <li><p><strong>University of California, Berkeley</strong> <br>
Summer Session, Jul 2016 - Aug 2016</p></li> <li><p><strong>Beijing University of Posts and Telecommunications</strong> <br>
B.Eng. in Electronic Engineering, Sept 2015 - Jun 2019</p></li></ul> <h2 id="internship">Internship</h2> <ul><li><strong>Microsoft Research Asia</strong> (full-time, onsite) <br>
Intern at Data, Knowledge and Intelligence group, Aug 2020 - Feb 2021
<ul><li>Contributed to the research on Table2Charts.</li> <li>Delivered Table2Charts technique to Bing search and to Excel spreadsheet intelligence.</li> <li>Designed multilingual key-phrase extraction algorithm for questionnaire word cloud used in Forms Ideas and in Teams poll.</li></ul></li></ul> <h2 id="research-experience">Research Experience</h2> <ul><li><p><strong>Geometric Computing Lab, New York University</strong> <br>
Independent project, supervised by <a href="http://web.uvic.ca/~teseo/" target="_blank" rel="noopener noreferrer">Teseo Schneider<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> and <a href="https://cims.nyu.edu/gcl/daniele.html" target="_blank" rel="noopener noreferrer">Daniele Panozzo<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, Sept 2022 - Apr 2023 <br>
Worked on GPU accelerated contact simulations in PolyFEM library.</p></li> <li><p><strong>CILVR Lab, New York University</strong> <br>
Independent project, supervised by <a href="http://iacercalixto.github.io" target="_blank" rel="noopener noreferrer">Iacer Calixto<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> and <a href="http://claravania.github.io" target="_blank" rel="noopener noreferrer">Clara Vania<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, Mar 2020 - May 2021 <br>
Worked on learning robust mulilingual multimodal knowledge graph representations.</p></li> <li><p><strong>Center for Speech and Language Technologies, Tsinghua University</strong> <br>
Research intern, supervised by <a href="http://wangd.cslt.org" target="_blank" rel="noopener noreferrer">Dong Wang<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, 2019  <br>
Worked on ancient Chinese poetry generation.</p></li></ul> <h2 id="publication">Publication</h2> <div class="md-card show-border"><div class="card-image"><img src="/projects/01.png" alt></div> <div class="card-content"><p><strong>MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI</strong></p> <p>Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, <strong>Yibo Liu</strong>, Wenhao Huang, Huan Sun, Yu Su, Wenhu Chen</p> <p><em>arXiv</em> 2311.16502, Nov. 2023</p> <p>[<a href="https://arxiv.org/abs/2311.16502" target="_blank" rel="noopener noreferrer">Paper<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://mmmu-benchmark.github.io" target="_blank" rel="noopener noreferrer">Web Page<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/02.png" alt></div> <div class="card-content"><p><strong>Endowing Language Models with Multimodal Knowledge Graph Representations</strong></p> <p>Ningyuan Huang, Yash R. Deshpande, <strong>Yibo Liu</strong>, Houda Alberts, Kyunghyun Cho, Clara Vania, Iacer Calixto</p> <p><em>arXiv</em> 2206.13163, Jun. 2022</p> <p>[<a href="https://arxiv.org/abs/2206.13163" target="_blank" rel="noopener noreferrer">Paper<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/03.png" alt></div> <div class="card-content"><p><strong>VisualSem: a high-quality knowledge graph for vision and language</strong></p> <p>Houda Alberts, Ningyuan Huang, Yash Deshpande, <strong>Yibo Liu</strong>, Kyunghyun Cho, Clara Vania, Iacer Calixto</p> <p><em>Proceedings of the 1st Workshop on Multilingual Representation Learning</em>, pp. 138-152, Nov. 2021. <em>(colocated with EMNLP 2021)</em></p> <p>[<a href="https://aclanthology.org/2021.mrl-1.13.pdf" target="_blank" rel="noopener noreferrer">Paper<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="/files/MRL_slides.pdf">Slides</a>]</p> <p>I was the <strong>speaker</strong> of the presentation.</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/04.png" alt></div> <div class="card-content"><p><strong>Table2Charts: Recommending Charts by Learning Shared Table Representations</strong></p> <p>Mengyu Zhou, Qingtao Li, Xinyi He, Yuejiang Li , <strong>Yibo Liu</strong>, Wei Ji, Shi Han, Yining Chen, Daxin Jiang, Dongmei Zhang.</p> <p><em>Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, pp. 2389-2399, Aug. 2021</p> <p>[<a href="https://dl.acm.org/doi/pdf/10.1145/3447548.3467279" target="_blank" rel="noopener noreferrer">Paper<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://github.com/microsoft/Table2Charts" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <h2 id="open-source-projects">Open-Source Projects</h2> <div class="md-card show-border"><div class="card-image"><img src="/projects/1.png" alt></div> <div class="card-content"><p><strong>Neural Topic Model Library</strong></p> <ul><li>The first Python library containing all cutting-edge neural topic models.</li> <li>Refactored the code base framework and rewrote the interfaces, making it has compatible APIs with Gensim
LDA library.</li> <li>The second largest contributor to the repository. Collaborated with <a href="https://scholar.google.com/citations?user=FDeI9yUAAAAJ&amp;hl=zh-CN" target="_blank" rel="noopener noreferrer">Leilan Zhang<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>.</li></ul> <p>[<a href="https://github.com/zll17/Neural_Topic_Models/tree/dev_b" target="_blank" rel="noopener noreferrer">GitHub | 384 star ⭐️ | 77 fork<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/06.png" alt></div> <div class="card-content"><p><strong>Lock-free Linked List Library for GPUs</strong></p> <ul><li>The <strong>first</strong> library supporting all singly linked list operations on GPUs with CUDA.</li> <li>Achieveing 141x speedup for insertions and deletions compared to sequential operations.</li> <li>Individual contribution.</li></ul> <p>[<a href="https://github.com/xDarkLemon/Lock_Free_Linked_List_GPU/tree/master" target="_blank" rel="noopener noreferrer">GitHub<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/07.png" alt></div> <div class="card-content"><p><strong>MMMU Benchmark for Expert AGI</strong></p> <ul><li>Collected college-level multimodal questions and conducted empirical studies on error analysis.</li></ul> <p>[<a href="https://dl.acm.org/doi/pdf/10.1145/3447548.3467279" target="_blank" rel="noopener noreferrer">Paper<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://mmmu-benchmark.github.io" target="_blank" rel="noopener noreferrer">Web Page<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/10.png" alt></div> <div class="card-content"><p><strong>COIG-PC: Chinese Open Instruction Generalist Prompt Collection</strong></p> <ul><li>Collected prompts to facilitate the fine-tuning and optimization of Chinese language models.</li></ul> <p>[<a href="https://huggingface.co/datasets/BAAI/COIG-PC" target="_blank" rel="noopener noreferrer">Huggingface Dataset<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <h2 id="blog-posts">Blog Posts</h2> <p><a href="/article/">→ Full list</a></p> <div class="md-card show-border"><div class="card-image"><img src="/projects/08.png" alt></div> <div class="card-content"><p><strong>2021科大讯飞鸟鸣识别比赛总结</strong></p> <p>鸟类鸣叫声识别挑战赛旨在增强自动鸟类鸣叫声识别技术，预测出每个测试音频中出现的鸟类物种。比赛中，探索了多种特征提取方法、数据增强方法，对音频频谱图使用图像分类算法进行分类，探索了多种模型，包括CNN，CNN特征提取+序列模型（LSTM/Transformer），以及Vision Transformer。最终使用模型集成提升效果。</p> <p>[<a href="/article/bird_song.html">full article</a>] [<a href="https://github.com/xDarkLemon/BirdRec" target="_blank" rel="noopener noreferrer">code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/09.png" alt></div> <div class="card-content"><p><strong>Expressive Power, Generalization, and Optimization of Graph Neural Networks: A Survey</strong></p> <p>Summarized the theoretic frameworks of GNN’s expressive power; summarized the generalization bounds,
the generalization ability of different GNNs, and the methods to improve generalization ability; stated the
explanation of over-fitting problem and summarized the optimization methods.</p> <p>[<a href="/files/GNN_Survey.pdf">full article</a>]</p></div></div> <h2 id="teaching">Teaching</h2> <p><strong>Teaching Assistant</strong> for CSC503: Data Mining</p> <p>Conduct laboratory sessions for a class comprising 30 students, proctor the final exam.</p> <h2 id="hobbies">Hobbies</h2> <p><strong>Cycling</strong>: Completed a ride around Qinghai Lake covering a distance of 360 kilometers in 5 days in 2015.</p> <p><strong>Snowboarding</strong>: Proficient at an intermediate level.</p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated:</span> <span class="time">12/19/2023, 8:40:08 PM</span></div></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.da6b8446.js" defer></script><script src="/assets/js/2.4d7c2de1.js" defer></script><script src="/assets/js/7.9b937e51.js" defer></script><script src="/assets/js/4.80216183.js" defer></script><script src="/assets/js/5.93671bdf.js" defer></script>
  </body>
</html>
